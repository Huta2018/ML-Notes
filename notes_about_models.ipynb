{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43cb5ca8-684e-49f6-9ac8-40c48bd8abc2",
   "metadata": {},
   "source": [
    "## This notebook contains some notes about various Machine learning models.This will make easy to learn and read all aspects of ML. I will try to apply some models from scratch as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44db27b-a5d6-4c26-8e00-4006d4200026",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9772ca-6a44-4927-87e4-c9cdacc38e45",
   "metadata": {},
   "source": [
    "In this case the relationship between dependent and independent variable is modeled as a linear regression\n",
    "- y = $\\beta_{0}$ + $\\beta{1}$X + $\\epsilon$\n",
    "- It is used for simple prediction task with continuous data, when relation between X and y is approximately linear\n",
    "## Assumptions\n",
    "- Linearity\n",
    "- Independence\n",
    "- Homosedasticity (constant variance of error)\n",
    "- Noramlity of errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9ddb22-82f5-4ba8-8441-e72529b4b764",
   "metadata": {},
   "source": [
    "## Ridge Regression (L2 Regularization)\n",
    "- It is a regularized version of linear regression which adds penalty to the coefficients, shrinking them towrads zero. This helps reduced overfitting, specially in the case with multicollenarity (correlated independent variables)\n",
    "- ### Ridge Regression Loss Function\n",
    "$$L = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^{p} w_j^2$$\n",
    "\n",
    "- $y_i$ → Actual values\n",
    "- $\\hat{y}_i$ → Predicted values\n",
    "- $w_j$ → Model coefficients\n",
    "- $λ$  → Regularization parameter\n",
    "- $n$ → Number of samples\n",
    "- $p$ → Number of features\n",
    "## When to use L2 regularization\n",
    "- When multicollenarity exists between features\n",
    "- We want to improve model generalization by reducing complexity\n",
    "- In general regularization is a technique that helps prevent overfitting problem. The name regularization occurs because it helps keeping the parameters regular or normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8803e1e-535c-4814-87b8-f5c303d9062f",
   "metadata": {},
   "source": [
    "## Least absolute shrinkage and selection operator (L1 Regularization)\n",
    "- It adds $L{1}$ penalty to the coefficients which results in some coefficient being set to zero, which effectively performs feature selection.\n",
    "$$L = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^{p} |w_j|$$\n",
    "- $y_i$ → Actual values\n",
    "- $\\hat{y}_i$ → Predicted values\n",
    "- $w_j$ → Model coefficients\n",
    "- $λ$  → Regularization parameter\n",
    "- $n$ → Number of samples\n",
    "- $p$ → Number of features\n",
    "\n",
    "# When to use LASSO\n",
    "- When you want to perform feature selection or when you have many features but expect only a few to be significant.\n",
    "- Adavantages: Useful for sparse dataset, as it automatically selects relevant features by driving some coefficient to zero.\n",
    "- Primary goal of LASSO is to find a balance between model simplicity and accuracy. It achieves this by adding a penalty term to the traditional linear regression model, which encourages sparese solutions where some coefficient are forced to be exactly set zero.\n",
    "- LASSO procedure encourages simple sparse models (i.e. models with fewer parameters). This particular type of regression is well suited for models showing high level of multicollenarity or when you want to automate certain parts of model selection ,  like variable selection/parameter eliminations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999916ca-6980-405a-8c72-4d045e0293cf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
